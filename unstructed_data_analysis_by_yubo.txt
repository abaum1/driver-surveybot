# -*- coding: utf-8 -*-

from openai import OpenAI
import io
import pandas as pd
import numpy as np
import json
from collections import Counter


def connect_to_openai(prompt):
    

    # 1. 调用 GPT
    stream = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        stream=True,
    )
    # 2. 拼接流式返回结果
    result_io = io.StringIO()
    for chunk in stream:
        content = chunk.choices[0].delta.content
        if content is not None:
            result_io.write(content)

    # 获取最终结果
    result = result_io.getvalue()
    result_io.close()

    return result


# ====== Mapping & Analysis Functions ======
def map_similarity_to_factors(similarity_str, mapping):
    elements = [x.strip() for x in similarity_str.split(',') if x.strip()]
    factor_set = set()
    for element in elements:
        for key, values in mapping.items():
            if any(element.lower() == val.lower() for val in values):
                factor_set.add(key)
                break
    return ', '.join(sorted(factor_set))


def analyze_similarity_for_column(df, similarity, weights, question_name,
                                  analysis_template, aggregation_template):
    """
    Runs analysis for one similarity metric on a subset of rows.
    Adds raw similarity responses and mapped factors.
    Returns:
      - df_out: DataFrame with original index, raw similarity column, and mapped factors column
      - mapping_dict: synonym mapping from aggregation step
      - element_counts: Counter of raw elements across all rows
    """
    df_out = df.copy()
    # Raw response column named after similarity
    df_out[similarity] = np.nan

    for idx, row in df_out.iterrows():
        q1 = "Which schedule would you prefer for a pick?"
        q1_answer = row[question_name]
        q2 = (
            "Please say why you prefer 'Current Schedule' over 'Alternative Schedule'?"
            if q1_answer == 'Current Schedule'
            else "Please say why you prefer 'Alternative Schedule' over 'Current Schedule'?"
        )
        q2_response = row.get(f'Following {question_name} (First Answer)', '')
        q3_response = row.get(f'Following {question_name} (Second Answer)', '')
        q3 = (
            "Can you provide a bit more detail about why that affects your choice?"
            if pd.notna(q3_response) and str(q3_response) not in ['0', 'NaN']
            else ''
        )

        prompt = analysis_template.format(
            similarity=similarity,
            weights=weights,
            q1=q1,
            q1_answer=q1_answer,
            q2=q2,
            q2_response=q2_response,
            q3=q3,
            q3_response=q3_response
        )
        result = connect_to_openai(prompt)
        df_out.at[idx, similarity] = result

    # Aggregate raw factors
    all_elements = [res.split(', ') for res in df_out[similarity].dropna()]
    flattened = [e for sub in all_elements for e in sub]
    element_counts = Counter(flattened)
    unique_elements = list(element_counts.keys())

    # Build synonym mapping via OpenAI
    agg_prompt = aggregation_template.replace("{elements}", str(unique_elements))
    mapping_result = connect_to_openai(agg_prompt)
    mapping_dict = json.loads(mapping_result)

    # Map to final factors
    factors_col = f"Factors for {similarity}"
    df_out[factors_col] = df_out[similarity].apply(
        lambda x: map_similarity_to_factors(x, mapping_dict) if pd.notnull(x) else ""
    )

    return df_out[[similarity, factors_col]], mapping_dict, element_counts


# ====== Main Analysis ======
analysis_template = """# Survey Response Analysis Prompt

**Context:**
Researchers developed an LLM-based chatbot in Voiceflow to survey CTA bus drivers about their schedule preferences. Each survey response consists of:
- **Question 1:** "Which schedule would you prefer for a pick?"
  Options: "Current Schedule" (the driver’s current bus schedule) and "Alternative Schedule" (a similar schedule generated by a weighted KNN algorithm).
- **Question 2:**
  - If the driver chose "Current Schedule": "Please say why you prefer 'Current Schedule' over 'Alternative Schedule'?"
  - If the driver chose "Alternative Schedule": "Please say why you prefer 'Alternative Schedule' over 'Current Schedule'?"
- **Question 3:** (Optional – asked only if the answer to Question 2 is judged as insufficiently detailed) "Can you provide a bit more detail about why that effects your choice?"

**Algorithmic Weight Information:**
The "Alternative Schedule" is generated based on the {similarity} of the "Current Schedule", using a KNN-based approach with the following variables and their associated weights.
{weights}

**Input Placeholders:**
Replace the following placeholders with the actual response data:
- `{q1}`: Text of Question 1
- `{q1_answer}`: Respondent’s answer to Question 1
- `{q2}`: Text of Question 2
- `{q2_response}`: Respondent’s answer to Question 2
- `{q3}` (if applicable): Text of Question 3
- `{q3_response}` (if applicable): Respondent’s answer to Question 3

---

**Task:**
Analyze the provided survey response to extract all possible influencing factors behind the respondent’s schedule preference choice. Your analysis should consider:
1. **Direct and Implicit Factors:**
   - Identify explicit mentions and implicit references in `{q2_response}` and `{q3_response}` that reveal the influencing factors behind the choice.
   - Take into account the specific schedule characteristics (e.g., Pay, Max end time, etc.) as well as other personal or operational concerns mentioned by the respondent.

2. **Integration of Weight Details:**
   - Factor in the provided weight information to gauge the relative importance of each schedule characteristic.
   - Analyze if the respondent’s rationale indicates concerns over high-weight variables versus lower-weight factors.
   - Consider whether the respondent’s evaluation implicitly reflects an appreciation for the differing impact of these weighted variables.

---

**Output Format:**
Provide **only a single, comma-separated list** of the key influencing factors, with no bullet points, hyphens, newlines, or additional commentary. The output should exactly follow the format shown in the example below.
- Example: Pay, Max end time, Num weekend days off, Num senior routes

---
"""

aggregation_template = """# Element Aggregation and Factor Analysis Prompt

**Context:**
The following list of raw elements represents potential influencing factors extracted from survey responses regarding schedule preferences. Many of these elements express similar ideas and need to be consolidated into a smaller set of final factors with academic and professional terminology.

The raw list of elements is provided as:
{elements}

---

**Task:**
1. **Group Similar Elements:**
   - Analyze the provided list and group together elements that share similar meanings (e.g., different expressions that refer to compensation or scheduling issues).

2. **Consolidate into Final Factors:**
   - For each group, create a consolidated influencing factor with an academic/professional name.
   - Ensure that the final names capture the core concept of the grouped elements (e.g., "Compensation and Benefits", "Schedule Timing", "Work-Life Balance").

3. **Map Raw Elements to Final Factors:**
   - For each consolidated factor, list out the original elements that contributed to it.

---

**Output Format:**
Return the output as a structured mapping where each key is a final influencing factor and the corresponding value is a list of the raw elements grouped under that factor. For example:

{ "Compensation and Benefits": ["Pay", "more money", "Pays", "Maximizing paytime hours"], "Schedule Timing": ["Max end time", "Getting off earlier", "Earlier start time"], "Work-Life Balance": ["Num weekend days off", "Family considerations", "Work-life balance"] }

*Do not include any additional commentary or summary beyond the mapping output.*

---

**Instructions:**
- Use professional and concise language for naming the final factors.
- Ensure that the grouping logically aggregates elements that are conceptually similar.
- Only include factors that have support from at least one raw element from the list.

---
"""

# Load data
df = pd.read_csv('CTA Results.csv')

# Define metrics, weights, question mappings
similarity_columns = [
    "route similarity",
    "days off similarity",
    "run type and pay time similarity"
]
weights_dict = {
    "route similarity": """- **Pay:** 1.0
- **Max end time:** 1.0
- **Num swing:** 1.0
- **Num AM:** 1.0
- **Num PM:** 1.0
- **Num OWL:** 1.0
- **Num weekend days off:** 1.0
- **Has sat off:** 1.0
- **Has sun off:** 1.0
- **Num Mon Fri days off:** 5.0
- **Num midweek days off:** 5.0
- **Num senior routes:** 10.0
- **Num non senior routes:** 10.0
- **Num mixed routes:** 10.0""",
    "days off similarity": """- **Pay:** 1.0
- **Max end time:** 2.0
- **Num swing:** 1.0
- **Num AM:** 1.0
- **Num PM:** 1.0
- **Num OWL:** 1.0
- **Num weekend days off:** 15.0
- **Has sat off:** 15.0
- **Has sun off:** 15.0
- **Num Mon Fri days off:** 10.0
- **Num midweek days off:** 10.0
- **Num senior routes:** 1.0
- **Num non senior routes:** 1.0
- **Num mixed routes:** 1.0""",
    "run type and pay time similarity": """- **Pay:** 10.0
- **Max end time:** 2.0
- **Num swing:** 10.0
- **Num AM:** 10.0
- **Num PM:** 10.0
- **Num OWL:** 10.0
- **Num weekend days off:** 5.0
- **Has sat off:** 1.0
- **Has sun off:** 1.0
- **Num Mon Fri days off:** 5.0
- **Num midweek days off:** 5.0
- **Num senior routes:** 1.0
- **Num non senior routes:** 1.0
- **Num mixed routes:** 1.0""",
}
question_name_dict = {
    "route similarity": "Question 2",
    "days off similarity": "Question 3",
    "run type and pay time similarity": "Question 4",
}

# Prepare a DataFrame to hold analysis
df_analysis = df.copy()
# Container for aggregated summary
aggregated_analysis = {}

for sim in similarity_columns:
    aggregated_analysis[sim] = {}
    question_col = question_name_dict[sim]

    for schedule_type in ['Current Schedule', 'Alternative Schedule']:
        subset_idx = df_analysis[df_analysis[question_col] == schedule_type].index
        if subset_idx.empty:
            print(f"No rows for {sim} under {schedule_type}")
            continue

        subset = df_analysis.loc[subset_idx]
        analyzed_df, mapping_dict, raw_counts = analyze_similarity_for_column(
            subset, sim, weights_dict[sim], question_col,
            analysis_template, aggregation_template
        )

        # Column names for raw and factor results
        raw_col = f"{sim} raw ({schedule_type})"
        factors_col = f"Factors_{sim.replace(' ', '_')}_{schedule_type.replace(' ', '_')}"

        # Assign results back into master DataFrame
        df_analysis.loc[subset_idx, raw_col] = analyzed_df[sim]
        df_analysis.loc[subset_idx, factors_col] = analyzed_df[f"Factors for {sim}"]

        # Summarize counts for this block
        final_counts = Counter(
            factor.strip()
            for cell in analyzed_df[f"Factors for {sim}"].dropna()
            for factor in cell.split(',') if factor.strip()
        )

        aggregated_analysis[sim][schedule_type] = {
            'raw_counts': dict(raw_counts),
            'synonym_mapping': mapping_dict,
            'final_factor_counts': dict(final_counts)
        }

        print(f"-- {sim} under {schedule_type} factor counts -- {dict(final_counts)}")

# Export a single combined CSV
output_file = 'CTA_Analyzed.csv'
df_analysis.to_csv(output_file, index=False)
print(f"Analysis complete. Results saved to {output_file}.")