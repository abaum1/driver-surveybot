# -*- coding: utf-8 -*-

from openai import OpenAI
import io
import pandas as pd
import numpy as np
import json
from collections import Counter
import sys
import os
from pathlib import Path
from dotenv import load_dotenv


sys.path.append(os.path.abspath(os.path.join(os.getcwd(), "..")))

ONE_DRIVE_WORKFORCE_DATA_PATH = Path(
    "/Users/ameliabaum/OneDrive - Massachusetts Institute of Technology/workforce_planning_data/"
)
SURVEY_DATA_PATH = ONE_DRIVE_WORKFORCE_DATA_PATH / "survey_alternatives_data/"


def connect_to_openai(prompt):
    load_dotenv()
    API_KEY = os.getenv("OPENAI_API_KEY")

    if not API_KEY:
        raise ValueError(
            "API key not found. Please set OPENAI_API_KEY in your .env file."
        )
    client = OpenAI(api_key=API_KEY)

    # 1. 调用 GPT
    stream = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        stream=True,
    )
    # 2. 拼接流式返回结果
    result_io = io.StringIO()
    for chunk in stream:
        content = chunk.choices[0].delta.content
        if content is not None:
            result_io.write(content)

    # 获取最终结果
    result = result_io.getvalue()
    result_io.close()

    return result


# ====== Mapping & Analysis Functions ======
def map_similarity_to_factors(similarity_str, mapping):
    elements = [x.strip() for x in similarity_str.split(",") if x.strip()]
    factor_set = set()
    for element in elements:
        for key, values in mapping.items():
            if any(element.lower() == val.lower() for val in values):
                factor_set.add(key)
                break
    return ", ".join(sorted(factor_set))


def analyze_similarity_for_column(
    df, similarity, weights, question_name, analysis_template, aggregation_template
):
    """
    Runs analysis for one similarity metric on a subset of rows.
    Adds raw similarity responses and mapped factors.
    Returns:
      - df_out: DataFrame with original index, raw similarity column, and mapped factors column
      - mapping_dict: synonym mapping from aggregation step
      - element_counts: Counter of raw elements across all rows
    """
    df_out = df.copy()
    # Raw response column named after similarity
    df_out[similarity] = np.nan

    for idx, row in df_out.iterrows():
        q1 = "Which schedule would you prefer for a pick?"
        q1_answer = row[question_name]
        q2 = (
            "Please say why you prefer 'Current Schedule' over 'Alternative Schedule'?"
            if q1_answer == "Current Schedule"
            else "Please say why you prefer 'Alternative Schedule' over 'Current Schedule'?"
        )
        q2_response = row.get(f"Following {question_name} (First Answer)", "")
        q3_response = row.get(f"Following {question_name} (Second Answer)", "")
        q3 = (
            "Can you provide a bit more detail about why that affects your choice?"
            if pd.notna(q3_response) and str(q3_response) not in ["0", "NaN"]
            else ""
        )

        prompt = analysis_template.format(
            similarity=similarity,
            # weights=weights,
            q1=q1,
            q1_answer=q1_answer,
            q2=q2,
            q2_response=q2_response,
            q3=q3,
            q3_response=q3_response,
        )
        result = connect_to_openai(prompt)
        df_out.at[idx, similarity] = result

    # Aggregate raw factors
    all_elements = [res.split(", ") for res in df_out[similarity].dropna()]
    flattened = [e for sub in all_elements for e in sub]
    element_counts = Counter(flattened)
    unique_elements = list(element_counts.keys())

    # Build synonym mapping via OpenAI
    agg_prompt = aggregation_template.replace("{elements}", str(unique_elements))
    mapping_result = connect_to_openai(agg_prompt)
    mapping_dict = json.loads(mapping_result)

    # Map to final factors
    factors_col = f"Factors for {similarity}"
    df_out[factors_col] = df_out[similarity].apply(
        lambda x: map_similarity_to_factors(x, mapping_dict) if pd.notnull(x) else ""
    )

    return df_out[[similarity, factors_col]], mapping_dict, element_counts


# ====== Main Analysis ======
analysis_template = """# Survey Response Analysis Prompt

**Context:**
Researchers developed an LLM-based chatbot in Voiceflow to survey CTA bus drivers about their schedule preferences. Each survey response consists of:
- **Question 1:** "Which schedule would you prefer for a pick?"
  Options: "Current Schedule" (the driver’s current working schedule) and "Alternative Schedule" (a similar schedule generated by a weighted KNN algorithm, that differs along some key factors).
- **Question 2:**
  - If the driver chose "Current Schedule": "Please say why you prefer 'Current Schedule' over 'Alternative Schedule'?"
  - If the driver chose "Alternative Schedule": "Please say why you prefer 'Alternative Schedule' over 'Current Schedule'?"
- **Question 3:** (Optional – asked only if the answer to Question 2 is judged as insufficiently detailed) "Can you provide a bit more detail about why that effects your choice?"


**Input Placeholders:**
Replace the following placeholders with the actual response data:
- `{q1}`: Text of Question 1
- `{q1_answer}`: Respondent’s answer to Question 1
- `{q2}`: Text of Question 2
- `{q2_response}`: Respondent’s answer to Question 2
- `{q3}` (if applicable): Text of Question 3
- `{q3_response}` (if applicable): Respondent’s answer to Question 3

---

**Task:**
Analyze the provided survey response to extract all possible influencing factors behind the respondent’s schedule preference choice. Your analysis should consider:
   1. Identify explicit mentions and implicit references in `{q2_response}` and `{q3_response}` that reveal the influencing factors behind the choice.
   2. Take into account the specific schedule characteristics (e.g., Pay, working times, etc.) as well as other personal or operational concerns mentioned by the respondent.
   3. Use the provided context to understand the meaning of operator phrases and how they relate to the CTA bus driver’s work environment.


---

**Output Format:**
Provide **only a single, comma-separated list** of the key influencing factors, with no bullet points, hyphens, newlines, or additional commentary. The output should exactly follow the format shown in the example below.
- Example: Pay, schedule timing, days off, preferred routes

---
"""

aggregation_template = """# Element Aggregation and Factor Analysis Prompt

**Context:**
The following list of raw elements represents potential influencing factors extracted from survey responses regarding schedule preferences. Many of these elements express similar ideas and need to be consolidated into a smaller set of final factors using the vernacular of public transit operations and scheduling.

The raw list of elements is provided as:
{elements}

___
**Additional Domain Context (Glossary for Mapping):**

Use the following context to better understand the meaning of operator phrases:

- "Pay", "more money", "pay hours", or "maximizing paytime", "extra hours" → refer to **Higher Compensation**.
- "Getting off earlier", "earlier end time", "get off early" → refer to **Earlier Schedule** or **Schedule Timing**.
- "Weekends off", "more weekends off", "Saturday off" or "Sunday off", "Monday thru Friday" → usually indicate **Days Off** or **Weekend Days Off**.
- ""spending time with family", "church", "kids", or "family time", "exercise", "flexibility" → relate to **Work-Life Balance**.
- "Same start time every day", "consistent work hours", or "predictable schedule" → relate to **Schedule Consistency**.
- "Closer to home", "shorter commute", or "garage location" → imply **Commute Characteristics**.
- "Familiar routes", "same routes as before", or "knows the route", "prefer street", "traffic", "my street" → refer to **Job Familiarity** or **Route Preferences**.
- "Less stress", "physical demands", "break time", or "more rest between shifts" → may suggest **Mental Health**, **Recovery Time**, or **Shift Fatigue**.
- "safety", "Safer", "unsafe", "violent", "crime", "dangerous" → refer to **Safety Concerns**.
- "3 days off", "prefer blocks", "like block runs", "more days off → refer to **Prefer Block Runs**.

You may use these examples to help determine how to group and label ambiguous or idiosyncratic responses.


---

**Task:**
1. **Group Similar Elements:**
   - Analyze the provided list and group together elements that share similar meanings (e.g., different responses that are talking about the same issues ).

2. **Consolidate into Final Factors:**
   - For each group, create a consolidated influencing factor with a term appropriate for the public transportation professional context. 
   - Avoid synonyms or rephrasings across factors. Ex: "Schedule Flexibility" and "Flexibility of Schedule" should be consolidated into one factor.
   - Ensure that the final names capture the core concept of the grouped elements (e.g., "Compensation and Benefits", "Schedule Timing", "Work-Life Balance").

3. **Strictly Limit to 15 Final Factors:**
   - You **must return no more than 15 factors** total. If there are more than 15 possible themes, combine overlapping ones into broader categories.
   - Think of this as dimensionality reduction: prioritize clarity and parsimony over granularity.

3. **Map Raw Elements to Final Factors:**
   - For each consolidated factor, list out the original elements that contributed to it.

---

**Output Format:**
Return the output as a structured mapping where each key is a final influencing factor and the corresponding value is a list of the raw elements grouped under that factor. For example:

{ "Compensation and Benefits": ["Pay", "more money", "Pays", "Maximizing paytime hours"], "Schedule Timing": ["Max end time", "Getting off earlier", "Earlier start time"], "Work-Life Balance": ["Num weekend days off", "Family considerations", "Work-life balance"] }

*Do not include any additional commentary or summary beyond the mapping output.*

---

**Instructions:**
- Use professional and concise language for naming the final factors.
- Ensure that the grouping logically aggregates elements that are conceptually similar.
- Ensure that the final factors are distinct and do not overlap in meaning.

---
"""


# Load data
df = pd.read_csv(
    ONE_DRIVE_WORKFORCE_DATA_PATH / "survey_alternatives_data/CTA Results.csv"
)

# Define metrics, weights, question mappings
question_descriptions = [
    "route similarity",
    "days off similarity",
    "run type and pay time similarity",
]
weights_dict = {
    "route similarity": """- **Pay:** 1.0
- **Max end time:** 1.0
- **Num swing:** 1.0
- **Num AM:** 1.0
- **Num PM:** 1.0
- **Num OWL:** 1.0
- **Num weekend days off:** 1.0
- **Has sat off:** 1.0
- **Has sun off:** 1.0
- **Num Mon Fri days off:** 5.0
- **Num midweek days off:** 5.0
- **Num senior routes:** 10.0
- **Num non senior routes:** 10.0
- **Num mixed routes:** 10.0""",
    "days off similarity": """- **Pay:** 1.0
- **Max end time:** 2.0
- **Num swing:** 1.0
- **Num AM:** 1.0
- **Num PM:** 1.0
- **Num OWL:** 1.0
- **Num weekend days off:** 15.0
- **Has sat off:** 15.0
- **Has sun off:** 15.0
- **Num Mon Fri days off:** 10.0
- **Num midweek days off:** 10.0
- **Num senior routes:** 1.0
- **Num non senior routes:** 1.0
- **Num mixed routes:** 1.0""",
    "run type and pay time similarity": """- **Pay:** 10.0
- **Max end time:** 2.0
- **Num swing:** 10.0
- **Num AM:** 10.0
- **Num PM:** 10.0
- **Num OWL:** 10.0
- **Num weekend days off:** 5.0
- **Has sat off:** 1.0
- **Has sun off:** 1.0
- **Num Mon Fri days off:** 5.0
- **Num midweek days off:** 5.0
- **Num senior routes:** 1.0
- **Num non senior routes:** 1.0
- **Num mixed routes:** 1.0""",
}
question_name_dict = {
    "route similarity": "Question 2",
    "days off similarity": "Question 3",
    "run type and pay time similarity": "Question 4",
}

# Containers
df_analysis = df.copy()
all_raw_elements = []
raw_results_by_question = {}

# STEP 1: Run LLM and collect all raw elements
for question in question_descriptions:
    raw_results_by_question[question] = {}
    question_col = question_name_dict[question]

    for schedule_type in ["Current Schedule", "Alternative Schedule"]:
        subset_idx = df_analysis[df_analysis[question_col] == schedule_type].index
        if subset_idx.empty:
            print(f"No rows for {question} under {schedule_type}")
            continue

        subset = df_analysis.loc[subset_idx]
        analyzed_df, _, _ = analyze_similarity_for_column(
            subset,
            question,
            weights_dict[question],
            question_col,
            analysis_template,
            aggregation_template,
        )

        for idx, raw_response in analyzed_df[question].dropna().items():
            raw_elements = [e.strip() for e in raw_response.split(",") if e.strip()]
            all_raw_elements.extend(raw_elements)
            raw_results_by_question[question][idx] = {
                "schedule_type": schedule_type,
                "raw_elements": raw_elements,
            }

        # Save raw string column for context
        raw_col = f"{question} raw ({schedule_type})"
        df_analysis.loc[subset_idx, raw_col] = analyzed_df[question]

# STEP 2: Create global 15-factor mapping from unique raw elements
unique_raw_elements = sorted(set(all_raw_elements))
agg_prompt = aggregation_template.replace("{elements}", str(unique_raw_elements))
mapping_result = connect_to_openai(agg_prompt)
global_mapping_dict = json.loads(mapping_result)

# Invert mapping for easier lookups
raw_to_factor = {}
for factor, raw_terms in global_mapping_dict.items():
    for term in raw_terms:
        raw_to_factor[term.strip()] = factor.strip()

# STEP 3: Apply mapping with full traceability
for question in question_descriptions:
    question_results = raw_results_by_question[question]

    for idx, record in question_results.items():
        schedule_type = record["schedule_type"]
        raw_elements = record["raw_elements"]

        factor_set = set()
        mapping_list = []

        for raw in raw_elements:
            factor = raw_to_factor.get(raw, "Unmapped")
            mapping_list.append(f"{raw} → {factor}")
            if factor != "Unmapped":
                factor_set.add(factor)

        # Save all to columns
        prefix = f"{question.replace(' ', '_')}_{schedule_type.replace(' ', '_')}"
        df_analysis.loc[idx, f"Raw_elements_{prefix}"] = ", ".join(raw_elements)
        df_analysis.loc[idx, f"Raw→Factor_map_{prefix}"] = " | ".join(mapping_list)
        df_analysis.loc[idx, f"Factors_{prefix}"] = ", ".join(sorted(factor_set))

# STEP 4: Optional summary of global factor usage
global_factor_counts = Counter()
for question in question_descriptions:
    for idx, record in raw_results_by_question[question].items():
        factor_str = df_analysis.loc[
            idx,
            f"Factors_{question.replace(' ', '_')}_{record['schedule_type'].replace(' ', '_')}",
        ]
        for factor in factor_str.split(","):
            factor = factor.strip()
            if factor:
                global_factor_counts[factor] += 1

print("\n=== Global Factor Usage Summary ===")
print(dict(global_factor_counts))


# Export a single combined CSV
output_file = "CTA_Analyzed_v4.csv"
df_analysis.to_csv(SURVEY_DATA_PATH / output_file, index=False)
print(f"Analysis complete. Results saved to {output_file}.")
